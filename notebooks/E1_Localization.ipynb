{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b23ca5b-a3f6-4370-b0df-c033b93e0313",
   "metadata": {},
   "source": [
    "# E1. Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce350074-8201-42b2-b2c6-8bd060551d5b",
   "metadata": {},
   "source": [
    "### Define all the imports\n",
    "Import all the dependencies required to launch the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f293c-eee8-4fb0-92a9-cc00a5522cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import main dependencies\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addecc1-5286-416b-a4af-766649e34064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to main repo folder for the imports\n",
    "_, dir = os.path.split(os.getcwd())\n",
    "if dir == 'notebooks': \n",
    "    os.chdir('..')\n",
    "    sys.path.append(os.getcwd())\n",
    "# Ignore warnings from pandas\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825593e-aafb-480a-8e8c-0de32754c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import methods from our local library\n",
    "from src.localization.PF import ParticleFilter\n",
    "from src.localization.EKF import ExtendedKalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d05ca-f5da-4601-a7af-e29da7d722df",
   "metadata": {},
   "source": [
    "### Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5108eaa-c5e1-42e0-8908-fc013c52f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset to be used for the following tests. \n",
    "dataset = \"data/MRCLAM_Dataset4\" # Dataset\n",
    "end_frame = 10000 # Extension of the dataset\n",
    "robot = 'Robot5' # Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e10fa1",
   "metadata": {},
   "source": [
    "### T1. Review EKF localization\n",
    "Review the ExtendedKalmanFilter() method, execute the EKF localization of the next code block, and answer the questions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ba578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Extended Kalman Filter object\n",
    "R = np.diagflat(np.array([1.0, 1.0, 10.0]))** 2\n",
    "Q = np.diagflat(np.array([300, 300, 1e16]))** 2\n",
    "ekf = ExtendedKalmanFilter(dataset, robot, end_frame, R, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51f49e",
   "metadata": {},
   "source": [
    "**T11** The EKF localisation algorithm iteratively executes the functions motion_update() and measurement_update() to propagate the robot's state estimate. Could you specify, respectively for each of the two functions, when are they called and what is their purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c204d",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0203f3a6",
   "metadata": {},
   "source": [
    "**T12** The ExtendedKalmanFilter() method inputs the R and Q matrices. Could you describe what are they used for and how they affect to the resulting localization estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf0b9d7",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ba28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34683515",
   "metadata": {},
   "source": [
    "### T2. Review PF localization\n",
    "Review the ParticleFilter() method and execute the PF localization of the next code block. Then answer the questions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be97775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Particle Filter object\n",
    "num_particles = 20\n",
    "motion_noise = np.array([0.1, 0.1, 0.1, 0.2, 0.2]) # Motion model noise [noise_x, noise_y, noise_theta, noise_v, noise_w]\n",
    "measurement_noise = np.array([0.1, 0.1]) # Measurement model noise (in meters / rad) [noise_range, noise_bearing]\n",
    "pf = ParticleFilter(dataset, robot, end_frame, num_particles, motion_noise, measurement_noise, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fad8c2",
   "metadata": {},
   "source": [
    "**T2.1** The PF localisation algorithm iteratively executes the functions motion_update(), measurement_update(), importance_sampling() and state_update(). Could you specify, the goal of each of the functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80566b4b",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ec5d3",
   "metadata": {},
   "source": [
    "**T2.1** The ParticleFilter() method inputs three different configuration parameters: num_particles, motion_noise, measurement_noise. Could you describe purpose and how they affect to the resulting estimation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bc0683",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e90c0",
   "metadata": {},
   "source": [
    "### T3. Benchmark\n",
    "Compare the EKF and the PF algorithms using diferent configurations for each algorithm and different datasets. For the comparison use the error metric introducced in previous lab sessions. You may also want to use the measurement density metric from the first lab to characterize the datasets complexity. \n",
    "\n",
    "The objective of this task is to be able to determine the localization algorithm and configuration that provides the best performance. In order to decide which model and configuration works best follow the next steps:\n",
    "1. Extract the benchmark metrics for each dataset and model configuaration.\n",
    "2. Represent the results in different types of plots (for instance catplot or correlation matrix).\n",
    "3. Analyze the results and extract conclusions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88bfe6e-a84e-47fd-9752-5e118d09278f",
   "metadata": {},
   "source": [
    "#### Extract error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee681b-d8a1-4cc4-91ad-39dce4ea61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"../data/MRCLAM_Dataset1\",\n",
    "            \"../data/MRCLAM_Dataset2\",\n",
    "            \"../data/MRCLAM_Dataset3\",\n",
    "            \"../data/MRCLAM_Dataset4\"]\n",
    "\n",
    "robots = ['Robot1',\n",
    "          'Robot2',\n",
    "          'Robot3',\n",
    "          'Robot4']\n",
    "\n",
    "\n",
    "\n",
    "errors = pd.DataFrame(columns=['dataset','robot','model_name','..'])\n",
    "\n",
    "#for ds in datasets:\n",
    "   #for rob in robots:\n",
    "        # Load data\n",
    "        \n",
    "        # Compute models \n",
    "        # EKF1 = ExtendedKalmanFilter(dataset, robot, end_frame, R1, Q1)\n",
    "        # ...\n",
    "        # ...\n",
    "        # models = [EKF1, EKF2, EKF3, PF1, PF2, PF2]\n",
    "        \n",
    "        # Get the three errors\n",
    "        #for m in models:\n",
    "            # compute error\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201d90-0c4d-4a15-b38f-1ef58babda02",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Represent metrics\n",
    "For instance you could use the catplot of the seaborn library. Feel free to use another informative plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96052ee0-3a9e-431e-a487-284c5aaa223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent metrics for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac5360-e20a-4c45-9104-486dc5c1b246",
   "metadata": {},
   "source": [
    "#### Analize metrics\n",
    "**T3.1** Analize the representations, and extract some conclusions regarding the performance of each of the model configurations used. Which would be the best suited method for offline execution? Why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a990c67a",
   "metadata": {},
   "source": [
    "(Answer here max 300 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2917039",
   "metadata": {},
   "source": [
    "**T3.2** Which would be the best suited method for online execution? Try to add the computation time as an extra metric for the assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55059414",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a129124",
   "metadata": {},
   "source": [
    "**T3.3** BONUS. How would you modify the PF filter to allow filter initialization without prior state belief?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339474f",
   "metadata": {},
   "source": [
    "(Answer here max 150 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c5f62f",
   "metadata": {},
   "source": [
    "\n",
    "**Delivery Instructions:**\n",
    "\n",
    "1. ðŸ“‚ Please download your work in both Notebook and Markdown formats. Simply navigate to: \n",
    "\n",
    "   - `File` > `Download as` > `Notebook`\n",
    "\n",
    "   - `File` > `Download as` > `Markdown`\n",
    "   \n",
    "\n",
    "2. ðŸ—œ Once you have the necessary files and any associated figures, kindly compress them into a single .zip file. When naming your file, please use the format: **E1_FirstName_LastName.zip**.\n",
    "\n",
    "\n",
    "3. ðŸ“¤ Finally, make sure to upload your .zip file to Aula Digital by the set deadline: **15/10/24**.\n",
    "\n",
    "Best of luck with your submission, and reach out if you have any questions!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
