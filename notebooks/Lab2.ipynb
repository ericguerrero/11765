{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b23ca5b-a3f6-4370-b0df-c033b93e0313",
   "metadata": {},
   "source": [
    "# L2. EKF Localization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce350074-8201-42b2-b2c6-8bd060551d5b",
   "metadata": {},
   "source": [
    "### Define all the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f293c-eee8-4fb0-92a9-cc00a5522cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5addecc1-5286-416b-a4af-766649e34064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to main repo folder for the imports\n",
    "_, dir = os.path.split(os.getcwd())\n",
    "if dir == 'notebooks': \n",
    "    os.chdir('..')\n",
    "    sys.path.append(os.getcwd())\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.localization.dead_reckoning import DeadReckoning\n",
    "from src.localization.EKF import ExtendedKalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12d05ca-f5da-4601-a7af-e29da7d722df",
   "metadata": {},
   "source": [
    "### Set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5108eaa-c5e1-42e0-8908-fc013c52f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset to read\n",
    "dataset = \"data/MRCLAM_Dataset2\" # Dataset\n",
    "end_frame = 15000 # Extension of the dataset\n",
    "robot = 'Robot3' # Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ab94c",
   "metadata": {},
   "source": [
    "### Execute DR estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24b4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dead reckoning object\n",
    "dr = DeadReckoning(dataset, robot, end_frame)\n",
    "dr.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e355ec2",
   "metadata": {},
   "source": [
    "### TASK 1. Execute EKF estimation\n",
    "Complete the extended kalman filter estimation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f751bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Extended Kalman Filter object\n",
    "R = np.diagflat(np.array([0.10, 0.10, 1.0]))** 2 \n",
    "Q = np.diagflat(np.array([100, 100, 1e16]))** 2\n",
    "ekf = ExtendedKalmanFilter(dataset, robot, end_frame, R, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab960d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "bc7949ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70ca1834-0344-4327-86c3-8769d110292a",
   "metadata": {},
   "source": [
    "### TASK 2. Compute path error metrics\n",
    "1. Build a dataframe joining the GT with the dead reckoning and EKF state estimation.\n",
    "\n",
    "\n",
    "2. Compute the $ATE$ using the groundtruth states $GT$, the dead reckoning estimated states $S_{DR}$ and the extended Kalman filter estimated states $S_{EKF}$. The $ATE$ is then the root mean square error (RMSE) of the individual timestamp errors over the whole trajectory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0fefe-3d4d-4f89-a0fd-dc00d57fd24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb89b54-8ea3-48a6-9bd5-d30cd05c8b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eadc24fb",
   "metadata": {},
   "source": [
    "### TASK 3. Iterate over diferent datasets\n",
    "Here we are interested on executing multiple experiments using different robots and datasets and get the error from previous blocks for all the experiments and enable further analisis.\n",
    "\n",
    "The iterative execution of different experiments will enable as to compare different localization algorithms on further lab sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88bfe6e-a84e-47fd-9752-5e118d09278f",
   "metadata": {},
   "source": [
    "#### Generate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee681b-d8a1-4cc4-91ad-39dce4ea61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"../data/MRCLAM_Dataset1\",\n",
    "            \"../data/MRCLAM_Dataset2\",\n",
    "            \"../data/MRCLAM_Dataset3\",\n",
    "            \"../data/MRCLAM_Dataset4\"]\n",
    "robots = ['Robot1',\n",
    "          'Robot2',\n",
    "          'Robot3',\n",
    "          'Robot4']\n",
    "\n",
    "results = pd.DataFrame(columns=['dataset','robot','length','duration','n_landmarks','distance','m_density','ate'])\n",
    "\n",
    "#for ds in datasets:\n",
    "   #for rob in robots:\n",
    "        # Load data\n",
    "        \n",
    "        # Get the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47201d90-0c4d-4a15-b38f-1ef58babda02",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Represent metrics\n",
    "For instance you could use the catplot of the seaborn library. Feel free to use another informative plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96052ee0-3a9e-431e-a487-284c5aaa223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent metrics for all experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ac5360-e20a-4c45-9104-486dc5c1b246",
   "metadata": {},
   "source": [
    "#### Analize metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ee518-a4b1-4ee5-a07d-de75edbb8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analize the results and provide the mean error metrics across the experiments performed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
